{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4904400-2f60-4a3e-9c8d-b7771b375408",
   "metadata": {},
   "source": [
    "# Datanotes (please ignore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb7612-9f24-4ea2-ac8a-16a64d8ef221",
   "metadata": {},
   "source": [
    "speaker - directed hyperedge part 1\n",
    "onstage - directed hyperedge part 2\n",
    "index - edge ids at highest reasonable granularity (I think)\n",
    "\n",
    "granularities:\n",
    "- act, scene\n",
    "- act, scene, stagegroup (unweighted)\n",
    "- act, scene, stagegroup (weighted by speech)\n",
    "- act, scene, stagegroup, speaker\n",
    "- act, scene, stagegroup, speaker, directed (speaker -> onstage)\n",
    "\n",
    "what we are currently lacking:\n",
    "- principled treatment of speech lacking who annotations (mostly if not only songs)\n",
    "- principled treatment of asides and other communication modifiers\n",
    "- principled treatment of unannotated deaths\n",
    "- principled treatment of prologues, epilogues, and inductions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e92375-51db-4b75-8313-d321ec05daed",
   "metadata": {},
   "source": [
    "- 'business': character actions, e.g., sleeping, waking, doing stuff (includes who)\n",
    "- 'delivery': asides, characters speaking in others' voices, other modifications to who hear what how\n",
    "- 'entrance': characters entering (includes who)\n",
    "- 'exit': characters leaving (includes who)\n",
    "- 'mixed': container for stage directions composed of multiple other types\n",
    "- 'modifier': characters appearing to be other characters\n",
    "- 'sound': music etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3f9b93-47f5-47b1-9f3a-5a93dab00891",
   "metadata": {},
   "source": [
    "### NB: There are some inconsistencies and weirdnesses even in this data - these are my WIP notes on what I observed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669bc3a5-75c1-4bca-a2c0-319b5957dca4",
   "metadata": {},
   "source": [
    "- MND: redundant castGroup wrapper for first castGroup\n",
    "- MND: weird encoding of stage directions with multiple types (e.g., business and sound)\n",
    "- MND: nested encoding of mixed stage directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf71579-a070-46d5-bd50-200117b35cb1",
   "metadata": {},
   "source": [
    "# Generating hypergraph representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390bf845-7609-4757-8ce8-51092d4e2af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0869cd05-77e2-4323-b526-4dfa844c7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperbard.preprocessing import get_filename_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1919e-b707-41d4-8e49-43e1898dcdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hypernetx as hnx\n",
    "import random\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5066de-cbb4-4f49-8459-ab159fb6ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6991cd-91d1-4a73-aa9e-f0b7112be388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99a4c1-91c1-485a-93f1-e1e575acea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../data\"\n",
    "files = sorted(glob(f\"{datapath}/*agg.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fcdfbe-5176-4f4a-9cd9-ef87eeb618c5",
   "metadata": {},
   "source": [
    "### Different hypergraph representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3e621-f6e6-44aa-b969-5c2267a53eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    file_short = get_filename_base(file).split(\"_\")[0]\n",
    "    print(file_short)\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    base_name = df.at[0,\"speaker\"].split(\"_\")[-1]\n",
    "    \n",
    "    # basic hg\n",
    "    edges = []\n",
    "    for (act, scene), group in df.groupby([\"act\", \"scene\", \"onstage\"]).agg(dict(n_tokens=\"sum\")).reset_index().groupby([\"act\",\"scene\"]):\n",
    "        joined_group = tuple(sorted(set(\" \".join(group.onstage).split())))\n",
    "        edges.append(joined_group)\n",
    "    H = hnx.Hypergraph(edges)\n",
    "    hdf = H.dataframe()\n",
    "    hdf.columns = hdf.columns.map(int)\n",
    "    hdf[sorted(hdf.columns)].to_csv(f\"../hypergraphs/{file_short}_act-scene.csv\")\n",
    "    \n",
    "    # draw\n",
    "    hnx.draw(H, \n",
    "         node_labels={n.uid:n.uid.split(\"_\")[0][1:] for n in H.nodes()}, \n",
    "         node_radius=dict((df.groupby([\"speaker\"]).agg({\"n_tokens\":\"sum\"}) / 2000 + 1).n_tokens.items()),\n",
    "         with_edge_labels=False, edges_kwargs=dict(edgecolors=[cm.viridis_r(x/len(H)) for x in range(len(H))]), \n",
    "         **layout_kwargs\n",
    "        )\n",
    "    plt.suptitle(file_short, y=1.0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../graphics/{file_short}_act-scene.pdf\")\n",
    "    plt.close()\n",
    "    \n",
    "    # more fine-grained hg\n",
    "    df_grouped = df.groupby([\"stagegroup\", \"onstage\", \"act\", \"scene\"]).agg({\"n_tokens\":\"sum\"}).reset_index()\n",
    "    df_grouped.onstage = df_grouped.onstage.map(lambda x: tuple(x.split()))\n",
    "    \n",
    "    Hs = {(act,scene): hnx.Hypergraph(dict(df_grouped.query(\"act == @act and scene == @scene\").onstage))\n",
    "          for (act,scene) in set(zip(df.act, df.scene))}\n",
    "\n",
    "    layout_kwargs = {'layout_kwargs': {'seed': 1234}}\n",
    "    n_acts = len(set(tup[0] for tup in Hs))\n",
    "    n_scenes = len(set(tup[1] for tup in Hs))\n",
    "    fig, ax = plt.subplots(n_scenes, n_acts, figsize=(n_acts*5,n_scenes*5))\n",
    "    for act, scene in sorted(Hs):\n",
    "        tax = ax[scene-1][act-1]\n",
    "        tax.set_title(f\"Act {act}, Scene {scene}\")\n",
    "        hnx.draw(Hs[(act,scene)], ax=tax,\n",
    "                 node_labels={n.uid:n.uid.split(\"_\")[0][1:] for n in Hs[(act,scene)].nodes()},\n",
    "                 node_radius=dict((df.query(\"act == @act and scene == @scene\").groupby([\"speaker\"]).agg({\"n_tokens\":\"sum\"}) / 250 + 1).n_tokens.items()),\n",
    "                 with_edge_labels=False, edges_kwargs=dict(edgecolors=[cm.viridis_r(x/len(H)) for x in range(len(H))]), **layout_kwargs)\n",
    "    for x,y in product(list(range(n_scenes)), list(range(n_acts))):\n",
    "        ax[x][y].axis('off')\n",
    "    plt.suptitle(file_short, y=1.0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../graphics/{file_short}_act-scene-stagegroup.pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f5ef7a-889f-4e40-aa5b-3104863a48e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9fb431-1278-4a42-a3c9-5ef3556a4ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}